{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>occupation_administrator</th>\n",
       "      <th>occupation_artist</th>\n",
       "      <th>occupation_doctor</th>\n",
       "      <th>occupation_educator</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Western</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>release_decade_1920.0</th>\n",
       "      <th>release_decade_1930.0</th>\n",
       "      <th>release_decade_1940.0</th>\n",
       "      <th>release_decade_1950.0</th>\n",
       "      <th>release_decade_1960.0</th>\n",
       "      <th>release_decade_1970.0</th>\n",
       "      <th>release_decade_1980.0</th>\n",
       "      <th>release_decade_1990.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>874724727</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>874724727</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>874724727</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>874724781</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>874724781</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  timestamp  rating  gender_F  gender_M  \\\n",
       "0      259      286  874724727       4         0         1   \n",
       "1      259      286  874724727       4         0         1   \n",
       "2      259      286  874724727       4         0         1   \n",
       "3      259      185  874724781       4         0         1   \n",
       "4      259      185  874724781       4         0         1   \n",
       "\n",
       "   occupation_administrator  occupation_artist  occupation_doctor  \\\n",
       "0                         0                  0                  0   \n",
       "1                         0                  0                  0   \n",
       "2                         0                  0                  0   \n",
       "3                         0                  0                  0   \n",
       "4                         0                  0                  0   \n",
       "\n",
       "   occupation_educator  ...  genre_Western  genre_unknown  \\\n",
       "0                    0  ...              0              0   \n",
       "1                    0  ...              0              0   \n",
       "2                    0  ...              0              0   \n",
       "3                    0  ...              0              0   \n",
       "4                    0  ...              0              0   \n",
       "\n",
       "   release_decade_1920.0  release_decade_1930.0  release_decade_1940.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   release_decade_1950.0  release_decade_1960.0  release_decade_1970.0  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      1                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   release_decade_1980.0  release_decade_1990.0  \n",
       "0                      0                      1  \n",
       "1                      0                      1  \n",
       "2                      0                      1  \n",
       "3                      0                      0  \n",
       "4                      0                      0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/clean/move-lens-100k-all.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MV-CTR\n",
    "\n",
    "The joint distribution is given by:\n",
    "\n",
    "$$\n",
    "P(f, z, \\Phi, \\theta | \\alpha, \\beta)\n",
    "    = \\prod_{t=1}^T P(\\theta | \\alpha) P(z_{t} | \\theta) \\prod_{x=1}^V  P(\\Phi^{(l)} | \\beta^{(l)}) P(f_{t}^{(l)} | z_t, \\Phi^{(l)}) \\\\\n",
    "    = \\prod_{k=1}^K \\theta_k^{\\sum_{t=1}^T z_{t} + \\alpha_k - 1} \\prod_{x=1}^V  (\\Phi_{xk}^{(l)})^{\\sum_{t=1}^T \\sum_{x=1}^V f_{tx}^{(l)}z_t + \\beta_k^{(l)} - 1} \n",
    "$$\n",
    "\n",
    "Marginalizing over $\\theta$ and $\\Phi$ gives:\n",
    "\n",
    "$$\n",
    "    P(f, z | \\alpha, \\beta) = \\int P(f, z, \\Phi_t, \\theta | \\alpha, \\beta) d\\theta d\\Phi \\\\\n",
    "        = \\frac{\\prod_{k=1}^K \\Gamma(n_k + \\alpha_k)}{\\Gamma(\\sum_{k=1}^K n_k + \\alpha_0)} \n",
    "            \\frac{\\prod_{x=1}^V \\prod_{k=1}^K \\Gamma(n_{xk} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{xk} + \\beta_0)}\n",
    "$$\n",
    "\n",
    "Where we defined:\n",
    "\n",
    "$$\n",
    "    n_k \\equiv \\sum_{t=1}^T r_t z_{tk} \\\\\n",
    "    n_{xk} \\equiv \\sum_{t=1}^T r_t f_{tx} z_{tk}\n",
    "$$\n",
    "\n",
    "where $r_t$ is the rating at $t$. Then, since $\\Gamma(n+1) = n \\Gamma(n)$:\n",
    "\n",
    "$$\n",
    "P(z_t = k' | z_{-t}, f, \\alpha, \\beta) \\propto P(f, z | \\alpha, \\beta) \\\\\n",
    "    \\propto \\prod_{k \\neq k'} \\Gamma(n_{k, -t} + \\alpha_k) \n",
    "        \\prod_{x=1}^V \\frac{\\Gamma(n_{xk, -t} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{xk, -t} + \\beta_0)}\n",
    "        \\Gamma(n_{k', -t} + \\alpha_{k'} + 1)\n",
    "        \\prod_{x = 1}^V \\frac{\\Gamma(n_{xk', -t} + \\beta_k' + 1)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{xk, -t} + \\beta_0 + 1)} \\\\\n",
    "    = \\prod_{k = 1}^K \\Gamma(n_{k, -t} + \\alpha_k) \n",
    "        \\prod_{x=1}^V \\frac{\\Gamma(n_{xk, -t} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{xk, -t} + \\beta_0)}\n",
    "        (n_{k', -t} + \\alpha_{k'}) \\prod_{x =1}^V \\frac{n_{xk', -t} + \\beta_{k'}}{\\sum_{x=1}^V \\sum_{k=1}^K n_{xk, -t} + \\beta_0} \\\\\n",
    "    \\propto (n_{k', -t} + \\alpha_{k'}) \\prod_{x = 1}^V  \\frac{n_{xk', -t} + \\beta_k}{\\sum_{x'=1}^V \\sum_{k=1}^K n_{xk', -t} + \\beta_0} \\\\\n",
    "$$\n",
    "\n",
    "where,\n",
    "$$\n",
    "    n_{k, -t} \\equiv \\sum_{t' \\neq t} r_{t'} z_{tk} \\\\\n",
    "    n_{xk, -t} \\equiv \\sum_{t' \\neq t} r_t f_{tx} z_{tk}\n",
    "$$\n",
    "\n",
    "Notice that the \"point\" removed from the products is that associated with a single rating point and feature-value. But because points stack up, we can simply pull out each aggregated rating simultaneously with the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23919"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "X = data.drop('rating', axis=1).to_numpy()\n",
    "r = data.rating.astype(int).to_numpy()\n",
    "\n",
    "V = data.shape[1] - 1\n",
    "K = 3\n",
    "T = len(data)\n",
    "\n",
    "a, b = 1, 1\n",
    "Phi = np.zeros((V, K))\n",
    "theta = np.zeros(K)\n",
    "\n",
    "# init topic assignment vector\n",
    "topic_assignment = np.random.choice(K, T)\n",
    "\n",
    "# init topic assignment counts\n",
    "_, n = np.unique(topic_assignment, return_counts=True) \n",
    "\n",
    "def m(x, k):\n",
    "    return (r * (topic_assignment == k).astype(int) * X[:, x]).sum()\n",
    "\n",
    "m(0, 0)\n",
    "\n",
    "z = 0\n",
    "for t in range(T):\n",
    "    # decrement\n",
    "    n[z] -= 1 \n",
    "    # sample from markov chain\n",
    "    z = np.random.multinomial(\n",
    "        1, pvals=(n + a) * np.array([[m(x, k) for k in range(K)] for x in range(V)]).prod()\n",
    "    ).argmax()\n",
    "    # update assignment\n",
    "    topic_assignment[t] = z\n",
    "    # increment\n",
    "    n[z] += 1 \n",
    "\n",
    "\n",
    "# # suppose we have a dataset with 30 datapoints\n",
    "# # with the following cluster assignment counts\n",
    "# n = np.array([10, 20, 70])\n",
    "\n",
    "# r = []\n",
    "# z_candidate = 0\n",
    "# for _ in range(1000000):\n",
    "#     n[z_candidate] -= 1 # decrement\n",
    "#     # a-K = 1\n",
    "#     z_candidate = np.random.multinomial(1, pvals=(n+1)/(n+1).sum()).argmax()\n",
    "#     n[z_candidate] += 1 # increment\n",
    "\n",
    "#     r.append(z_candidate)\n",
    "\n",
    "\n",
    "# # print distribution\n",
    "# t = 100000\n",
    "# (pd.Series(r)[:t].value_counts() / len(r[:t])).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[24947 24902 24718]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([23919, 71863,  7282,  2488,   565,  8356,  8792,  1835,  3212,\n",
       "        1749,   316,  1168,  4720,  2181,   770, 10350,  8289,  1235,\n",
       "         959,  2494, 20907,  3596,  4518,    75,  7593, 37922, 25523,\n",
       "       14531,  7835,  2098,   205, 14530,  7272,  1101,  2489,  8153,\n",
       "        3830,     0, 16184,   416,   772,  1712,  1773,  2466,  9501,\n",
       "        8601, 10790,  5857,   335,     0,     0,  1380,  1505,     0,\n",
       "        3418, 11823, 19073, 58583])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(topic_assignment, return_counts=True) \n",
    "\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "k = 0\n",
    "x = 0\n",
    "r * (topic_assignment == k).astype(int) @ X[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import multinomial\n",
    "\n",
    "multinomial(8, np.ones(3)/3).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MV-CTR 2\n",
    "\n",
    "The joint distribution is given by:\n",
    "\n",
    "$$\n",
    "P(f, z, \\Phi, \\theta | \\alpha, \\beta)\n",
    "    = \\prod_{k=1}^K\n",
    "    P(\\theta_k | \\alpha) \\prod_{t=1}^T P(z_{kt} | \\theta_k) \\prod_{x=1}^V  P(\\Phi_{kx} | \\beta_x) P(f_{tx} | z_{kt}, \\Phi_{kx}) \\\\\n",
    "    = \\prod_{k=1}^K \\theta_k^{\\sum_{t=1}^T z_{kt} + \\alpha_k - 1} \\prod_{x=1}^V  (\\Phi_{kx})^{\\sum_{t=1}^T f_{tx}z_{kt} + \\beta_x - 1} \n",
    "$$\n",
    "\n",
    "Marginalizing over $\\theta$ and $\\Phi$ gives:\n",
    "\n",
    "$$\n",
    "    P(f, z | \\alpha, \\beta) = \\int P(f, z, \\Phi_t, \\theta | \\alpha, \\beta) d\\theta d\\Phi \\\\\n",
    "        = \\frac{\\prod_{k=1}^K \\Gamma(n_k + \\alpha_k)}{\\Gamma(\\sum_{k=1}^K n_k + \\alpha_0)} \n",
    "            \\frac{\\prod_{x=1}^V \\Gamma(n_{kx} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V n_{kx} + \\beta_0)}\n",
    "$$\n",
    "\n",
    "Where we defined:\n",
    "\n",
    "$$\n",
    "    n_k \\equiv \\sum_{t=1}^T r_t z_{tk} \\\\\n",
    "    n_{kx} \\equiv \\sum_{t=1}^T r_t f_{tx} z_{tk}\n",
    "$$\n",
    "\n",
    "where $r_t$ is the rating at $t$. Then, since $\\Gamma(n+1) = n \\Gamma(n)$:\n",
    "\n",
    "$$\n",
    "P(z_t = k' | z_{-t}, f, \\alpha, \\beta) \\propto P(f, z | \\alpha, \\beta) \\\\\n",
    "    \\propto \\prod_{k \\neq k'} \\Gamma(n_{k, -t} + \\alpha_k) \n",
    "        \\prod_{x=1}^V \\frac{\\Gamma(n_{kx, -t} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{kx, -t} + \\beta_0)}\n",
    "        \\Gamma(n_{k', -t} + \\alpha_{k'} + 1)\n",
    "        \\prod_{x = 1}^V \\frac{\\Gamma(n_{k'x, -t} + \\beta_k' + 1)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{kx, -t} + \\beta_0 + 1)} \\\\\n",
    "    = \\prod_{k = 1}^K \\Gamma(n_{k, -t} + \\alpha_k) \n",
    "        \\prod_{x=1}^V \\frac{\\Gamma(n_{kx, -t} + \\beta_k)}{\\Gamma(\\sum_{x=1}^V \\sum_{k=1}^K n_{kx, -t} + \\beta_0)}\n",
    "        (n_{k', -t} + \\alpha_{k'}) \\prod_{x =1}^V \\frac{n_{xk', -t} + \\beta_{k'}}{\\sum_{x=1}^V \\sum_{k=1}^K n_{kx, -t} + \\beta_0} \\\\\n",
    "    \\propto (n_{k', -t} + \\alpha_{k'}) \\prod_{x = 1}^V  \\frac{n_{k'x, -t} + \\beta_k}{\\sum_{x'=1}^V \\sum_{k=1}^K n_{k'x, -t} + \\beta_0} \\\\\n",
    "$$\n",
    "\n",
    "where,\n",
    "$$\n",
    "    n_{k, -t} \\equiv \\sum_{t' \\neq t} r_{t'} z_{tk} \\\\\n",
    "    n_{xk, -t} \\equiv \\sum_{t' \\neq t} r_t f_{tx} z_{tk}\n",
    "$$\n",
    "\n",
    "Notice that the \"point\" removed from the products is that associated with a single rating point and feature-value. But because points stack up, we can simply pull out each aggregated rating simultaneously with the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('aplus_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bc95e45f665fe95fec2b3ef28eda59fe06862013fb7308bc53ca57b11a4292"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
